{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mXhSlcFx0v8G"
      ],
      "authorship_tag": "ABX9TyO04ZKqn07aIJso3yhEQbms",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bba894c49dd24a21ac2054c9e8948fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "BoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "BoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "BoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4980eed8bfd54f24bc0b8009c75a1622",
              "IPY_MODEL_8720000455f94da287b0ba35f33146dd"
            ],
            "layout": "IPY_MODEL_10a5b2e374524390929bf6c2acae799b"
          }
        },
        "4980eed8bfd54f24bc0b8009c75a1622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57fc1d10010c473985f67648eb61e041",
              "IPY_MODEL_45602c093ce449708767f8d594ab16ac"
            ],
            "layout": "IPY_MODEL_a59d6a7033eb4680babe78b9dbd62135"
          }
        },
        "8720000455f94da287b0ba35f33146dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_775aba541ddf4ae58f0529436500e3d9",
              "IPY_MODEL_36b51d5bbbd54267bd7a8917fdefa2f4"
            ],
            "layout": "IPY_MODEL_c5d2b7fae19949338cd2ed18795919ce"
          }
        },
        "10a5b2e374524390929bf6c2acae799b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57fc1d10010c473985f67648eb61e041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a4dd48329a44df6a1444e2bbf60da73",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_86a40d3a5ce242d6af7b1425fa36e449",
            "value": "Select a resolution:"
          }
        },
        "45602c093ce449708767f8d594ab16ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "299-1080p",
              "298-720p",
              "135-480p",
              "134-360p",
              "133-240p",
              "160-144p"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_4dcef2fa5d304d5ab738a04fac6fcaeb",
            "style": "IPY_MODEL_a98cce61b18c42b3a5ed0199eea73453"
          }
        },
        "a59d6a7033eb4680babe78b9dbd62135": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "775aba541ddf4ae58f0529436500e3d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3e8ef472c4d411fb5a2c25dc424a2b1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_18eaddd5c4d34db3aae804813c789f7d",
            "value": "Select an audio:"
          }
        },
        "36b51d5bbbd54267bd7a8917fdefa2f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "139-48kbps",
              "140-128kbps",
              "251-160kbps"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "index": 2,
            "layout": "IPY_MODEL_4f4cddbb71e049b992d5269f35741aa5",
            "style": "IPY_MODEL_5ce0b0ce324c454d91eac46261dc11dd"
          }
        },
        "c5d2b7fae19949338cd2ed18795919ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a4dd48329a44df6a1444e2bbf60da73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86a40d3a5ce242d6af7b1425fa36e449": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4dcef2fa5d304d5ab738a04fac6fcaeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a98cce61b18c42b3a5ed0199eea73453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3e8ef472c4d411fb5a2c25dc424a2b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18eaddd5c4d34db3aae804813c789f7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f4cddbb71e049b992d5269f35741aa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ce0b0ce324c454d91eac46261dc11dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CapitanMurloc/srt/blob/develop/Youtube_SRT_with_Whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ¦„ **Youtube SRT Whisper** - *Notebook creado por [Francisco Javier Estrella Rodriguez aka CapitanMurloc](https://www.youtube.com/channel/UCfDAxbIFtpUsxpA_eUnZQ_w)*"
      ],
      "metadata": {
        "id": "13d8DyiHtP0N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# â›© DescripciÃ³n\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VX6xHj0p0KaF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial setup"
      ],
      "metadata": {
        "id": "OxHGS6GkzB6l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VDiG80dKU8G-",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 1.- Install the required libs\n",
        "%%capture\n",
        "!pip install git+https://github.com/openai/whisper.git pytube datasets evaluate transformers[sentencepiece] sacremoses\n",
        "!apt install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.- Settings for subtitles\n",
        "#@markdown `Youtube` is the address of the video to generate subtitles.\n",
        "Youtube = \"https://www.youtube.com/watch?v=MUqNwgPjJvQ\" #@param {type:\"string\"}\n",
        "#@markdown `Source` is the language of the video to generate subtitles.\n",
        "Source = \"English\" #@param [\"English\", \"Spanish\"]\n",
        "#@markdown `Destiny` is the language of the video to generate subtitles.\n",
        "Destiny = \"Spanish\" #@param [\"English\", \"Spanish\"]\n",
        "\n",
        "language_source = \"en\" if Source == \"English\" else \"es\"\n",
        "language_destiny = \"es\" if Source == \"Spanish\" else \"en\"\n",
        "youtube_url = Youtube"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VEWBnOphyK5g"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3.- âš™ï¸ Help in choosing the right audio and video\n",
        "import re\n",
        "\n",
        "def extract_stream_movies(streams):\n",
        "  extracts = []\n",
        "  for stream in streams:\n",
        "    # Extract the type\n",
        "    stream_type = re.search('type=\"(\\w+)\"', stream).group(1)\n",
        "    progressive = re.search(r'progressive=\"(\\w+)\"', stream).group(1)\n",
        "    # Convert string to boolean\n",
        "    progressive = True if progressive == 'True' else False\n",
        "    if stream_type == 'video' and progressive == False:\n",
        "      # Extract the itag\n",
        "      tag = re.search('itag=\"(\\d+)\"', stream).group(1)\n",
        "      # Extract the resolution\n",
        "      res = re.search('res=\"(\\d+p)\"', stream).group(1)\n",
        "      # Append the itag and resolution to the list with separator '-'      \n",
        "      extracts.append(tag + '-' + res)\n",
        "  return extracts\n",
        "\n",
        "def extract_stream_audios(streams):\n",
        "  extracts = []\n",
        "  for stream in streams:\n",
        "    # Extract the type\n",
        "    stream_type = re.search('type=\"(\\w+)\"', stream).group(1)\n",
        "    progressive = re.search(r'progressive=\"(\\w+)\"', stream).group(1)\n",
        "    # Convert string to boolean\n",
        "    progressive = True if progressive == 'True' else False\n",
        "    if stream_type == 'audio' and progressive == False:\n",
        "      # Extract the itag\n",
        "      tag = re.search('itag=\"(\\d+)\"', stream).group(1)\n",
        "      # Extract the resolution\n",
        "      abr = re.search('abr=\"(\\d+kbps)\"', stream).group(1)\n",
        "      # Append the itag and resolution to the list with separator '-'      \n",
        "      extracts.append(tag + '-' + abr)\n",
        "  return extracts\n",
        "\n",
        "import ipywidgets as widgets\n",
        "streams = !pytube {youtube_url} --list\n",
        "del streams[0]\n",
        "movies = extract_stream_movies(streams)\n",
        "audios = extract_stream_audios(streams)\n",
        "movie = widgets.Dropdown(options=movies)\n",
        "audio = widgets.Dropdown(options=audios)\n",
        "widgets.Box([widgets.VBox([widgets.Label(value='Select a resolution:'), movie]),widgets.VBox([widgets.Label(value='Select an audio:'), audio])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "bba894c49dd24a21ac2054c9e8948fc1",
            "4980eed8bfd54f24bc0b8009c75a1622",
            "8720000455f94da287b0ba35f33146dd",
            "10a5b2e374524390929bf6c2acae799b",
            "57fc1d10010c473985f67648eb61e041",
            "45602c093ce449708767f8d594ab16ac",
            "a59d6a7033eb4680babe78b9dbd62135",
            "775aba541ddf4ae58f0529436500e3d9",
            "36b51d5bbbd54267bd7a8917fdefa2f4",
            "c5d2b7fae19949338cd2ed18795919ce",
            "7a4dd48329a44df6a1444e2bbf60da73",
            "86a40d3a5ce242d6af7b1425fa36e449",
            "4dcef2fa5d304d5ab738a04fac6fcaeb",
            "a98cce61b18c42b3a5ed0199eea73453",
            "c3e8ef472c4d411fb5a2c25dc424a2b1",
            "18eaddd5c4d34db3aae804813c789f7d",
            "4f4cddbb71e049b992d5269f35741aa5",
            "5ce0b0ce324c454d91eac46261dc11dd"
          ]
        },
        "cellView": "form",
        "id": "lKQlQQf16ZSQ",
        "outputId": "3a5f717d-6c30-4e2a-95f1-aa0b32b7bb20"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Box(children=(VBox(children=(Label(value='Select a resolution:'), Dropdown(options=('299-1080p', '298-720p', 'â€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bba894c49dd24a21ac2054c9e8948fc1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4.- ðŸŽ¥ Download movie and audio\n",
        "#@markdown `Movie` is the name of the video to be saved.\n",
        "Movie = \"movie.mp4\" #@param {type:\"string\"}\n",
        "#@markdown `Audio` is the name of the audio to be saved.\n",
        "Audio = \"audio.webm\" #@param {type:\"string\"}\n",
        "import pytube\n",
        "def download(url, tag, file_name):\n",
        "    try:\n",
        "        yt = pytube.YouTube(url)\n",
        "        stream = yt.streams.get_by_itag(tag)\n",
        "        stream.download(filename=file_name)\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "if download(youtube_url, movie.value.split('-')[0], Movie):\n",
        "  print(\"Movie downloaded successfully\")\n",
        "else:\n",
        "  print(\"Review -Help in choosing the right audio and video- See the list of available movies, check the resolutions.\")\n",
        "if download(youtube_url, audio.value.split('-')[0], Audio):\n",
        "  print(\"Audio downloaded successfully\")\n",
        "else:\n",
        "  print(\"Review -Help in choosing the right audio and video- See the list of available audios, check the resolutions.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "_1eZ2nG9WrN2",
        "outputId": "fa438190-e90b-462f-c79c-399cdb8260b1"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Movie downloaded successfully\n",
            "Audio downloaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teach the model the new concept (fine-tuning with Dreambooth)\n",
        "Execute this this sequence of cells to run the training process. The whole process may take from 15 min to 2 hours. (Open this block if you are interested in how this process works under the hood or if you want to change advanced training settings or hyperparameters)"
      ],
      "metadata": {
        "id": "mXhSlcFx0v8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!ffmpeg -i \"/content/Transformer models Encoders.mp4\" -i \"/content/Transformer models Encoders.webm\" -c:v copy -c:a aac output.mp4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KrDkSTJhbPp",
        "outputId": "a5065132-7db2-4994-afbb-c3992e4adf3c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/Transformer models Encoders.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : dash\n",
            "    minor_version   : 0\n",
            "    compatible_brands: iso6avc1mp41\n",
            "    creation_time   : 2021-06-09T13:52:34.000000Z\n",
            "  Duration: 00:04:45.83, start: 0.000000, bitrate: 336 kb/s\n",
            "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1920x1080 [SAR 1:1 DAR 16:9], 9 kb/s, 60 fps, 60 tbr, 15360 tbn, 120 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-06-09T13:52:34.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "Input #1, matroska,webm, from '/content/Transformer models Encoders.webm':\n",
            "  Metadata:\n",
            "    encoder         : google/video-file\n",
            "  Duration: 00:04:45.86, start: -0.007000, bitrate: 97 kb/s\n",
            "    Stream #1:0(eng): Audio: opus, 48000 Hz, stereo, fltp (default)\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (copy)\n",
            "  Stream #1:0 -> #0:1 (opus (native) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, mp4, to 'output.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : dash\n",
            "    minor_version   : 0\n",
            "    compatible_brands: iso6avc1mp41\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1920x1080 [SAR 1:1 DAR 16:9], q=2-31, 9 kb/s, 60 fps, 60 tbr, 15360 tbn, 15360 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-06-09T13:52:34.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 128 kb/s (default)\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 aac\n",
            "frame=17150 fps=1586 q=-1.0 Lsize=   16385kB time=00:04:45.84 bitrate= 469.6kbits/s speed=26.4x    \n",
            "video:11543kB audio:4462kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.372664%\n",
            "\u001b[1;36m[aac @ 0x5598a8337700] \u001b[0mQavg: 633.411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!whisper \"/content/output.mp4\" --task transcribe --language en --model large --output_dir audio_transcription"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a38Y6TTgWu-W",
        "outputId": "ac24e3d5-ec43-4a66-cfb0-9df4b08b3dec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.87G/2.87G [01:24<00:00, 36.5MiB/s]\n",
            "tcmalloc: large alloc 3087007744 bytes == 0x9cda000 @  0x7ff077a2b1e7 0x4b2590 0x5ad01c 0x5dcfef 0x58f92b 0x590c33 0x5e48ac 0x4d20fa 0x51041f 0x58fd37 0x50c4fc 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x50c4fc 0x5b4ee6 0x6005a3 0x607796 0x60785c 0x60a436 0x64db82 0x64dd2e 0x7ff077628c87 0x5b636a\n",
            "[00:00.000 --> 00:10.480]  In this video, we'll study the encoder architecture, an example of a popular encoder-only architecture\n",
            "[00:10.480 --> 00:14.680]  as BERT, which is the most popular model of its kind.\n",
            "[00:14.680 --> 00:18.480]  Let's first start by understanding how it works.\n",
            "[00:18.480 --> 00:20.960]  We'll use a small example using three words.\n",
            "[00:20.960 --> 00:25.360]  We use these as inputs and pass them through the encoder.\n",
            "[00:25.360 --> 00:30.120]  We retrieve a numerical representation of each word.\n",
            "[00:30.120 --> 00:35.180]  Here for example, the encoder converts those three words, welcome to NYC, in these three\n",
            "[00:35.180 --> 00:37.400]  sequences of numbers.\n",
            "[00:37.400 --> 00:42.440]  The encoder outputs exactly one sequence of numbers per input word.\n",
            "[00:42.440 --> 00:49.240]  This numerical representation can also be called a feature vector or a feature tensor.\n",
            "[00:49.240 --> 00:51.120]  Let's dive in this representation.\n",
            "[00:51.120 --> 00:56.200]  It contains one vector per word that was passed through the encoder.\n",
            "[00:56.200 --> 01:01.160]  Each of these vectors is a numerical representation of the word in question.\n",
            "[01:01.160 --> 01:05.600]  The dimension of that vector is defined by the architecture of the model.\n",
            "[01:05.600 --> 01:10.760]  For the base BERT model, it is 768.\n",
            "[01:10.760 --> 01:15.320]  These representations contain the value of a word but contextualized.\n",
            "[01:15.320 --> 01:21.200]  For example, the vector attributed to the word to isn't the representation of only the\n",
            "[01:21.200 --> 01:22.380]  to word.\n",
            "[01:22.380 --> 01:28.720]  It also takes into account the words around it, which we call the context.\n",
            "[01:28.720 --> 01:33.320]  As in it looks to the left context, the words on the left of the one we're studying.\n",
            "[01:33.320 --> 01:36.580]  Here the word welcome and the context on the right.\n",
            "[01:36.580 --> 01:42.080]  Here the word NYC and outputs a value for the word given its context.\n",
            "[01:42.080 --> 01:45.560]  It is therefore a contextualized value.\n",
            "[01:45.560 --> 01:53.420]  One could say that the vector of 768 values holds the meaning of the word within the text.\n",
            "[01:53.420 --> 01:57.320]  It does this thanks to the self-attention mechanism.\n",
            "[01:57.320 --> 02:02.800]  The self-attention mechanism relates to different positions or different words in a single sequence\n",
            "[02:02.800 --> 02:07.280]  in order to compute a representation of that sequence.\n",
            "[02:07.280 --> 02:11.420]  As we've seen before, this means that the resulting representation of a word has been\n",
            "[02:11.420 --> 02:15.880]  affected by other words in the sequence.\n",
            "[02:15.880 --> 02:20.000]  We won't dive into the specifics here, but we'll offer some further readings if you want\n",
            "[02:20.000 --> 02:25.120]  to get a better understanding at what happens under the hood.\n",
            "[02:25.120 --> 02:27.680]  So when should one use an encoder?\n",
            "[02:27.680 --> 02:32.160]  Encoders can be used as standalone models in a wide variety of tasks.\n",
            "[02:32.160 --> 02:36.840]  For example, BERT, arguably the most famous transformer model, is a standalone encoder\n",
            "[02:36.840 --> 02:37.840]  model.\n",
            "[02:37.840 --> 02:43.040]  At the time of release, it will be state-of-the-art in many sequence classification tasks, question\n",
            "[02:43.040 --> 02:48.200]  answering tasks, and masked language modeling to only cite a few.\n",
            "[02:48.200 --> 02:53.080]  The idea is that encoders are very powerful at extracting vectors that carry meaningful\n",
            "[02:53.080 --> 02:55.440]  information about a sequence.\n",
            "[02:55.440 --> 03:01.520]  This vector can then be handled down the road by additional neurons to make sense of it.\n",
            "[03:01.520 --> 03:06.400]  Let's take a look at some examples where encoders really shine.\n",
            "[03:06.400 --> 03:10.000]  First of all, masked language modeling, or MLM.\n",
            "[03:10.000 --> 03:13.360]  It's the task of predicting a hidden word in a sequence of words.\n",
            "[03:13.360 --> 03:18.320]  Here, for example, we have hidden the word between my and is.\n",
            "[03:18.320 --> 03:21.160]  This is one of the objectives with which BERT was trained.\n",
            "[03:21.160 --> 03:25.680]  It was trained to predict hidden words in a sequence.\n",
            "[03:25.680 --> 03:31.200]  Encoders shine in this scenario in particular, as bidirectional information is crucial here.\n",
            "[03:31.200 --> 03:35.200]  If we didn't have the words on the right, is, sylvain, and the dot, then there is very\n",
            "[03:35.200 --> 03:40.520]  little chance that BERT would have been able to identify name as the correct word.\n",
            "[03:40.520 --> 03:44.760]  The encoder needs to have a good understanding of the sequence in order to predict a masked\n",
            "[03:44.760 --> 03:50.520]  word, as even if the text is grammatically correct, it does not necessarily make sense\n",
            "[03:50.520 --> 03:55.280]  in the context of the sequence.\n",
            "[03:55.280 --> 03:59.640]  As mentioned earlier, encoders are good at doing sequence classification.\n",
            "[03:59.640 --> 04:04.460]  Sentiment analysis is an example of sequence classification.\n",
            "[04:04.460 --> 04:09.560]  The model's aim is to identify the sentiment of a sequence.\n",
            "[04:09.560 --> 04:14.600]  It can range from giving a sequence a rating from one to five stars if doing review analysis,\n",
            "[04:14.600 --> 04:20.320]  to giving a positive or negative rating to a sequence, which is what is shown here.\n",
            "[04:20.320 --> 04:25.940]  For example, here, given the two sequences, we use the model to compute a prediction and\n",
            "[04:25.940 --> 04:31.320]  to classify the sequences among these two classes, positive and negative.\n",
            "[04:31.320 --> 04:35.800]  While the two sequences are very similar, containing the same words, the meaning is\n",
            "[04:35.800 --> 05:02.360]  entirely different, and the encoder model is able to grasp that difference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora instalamos transformers para traducir del idioma ingles al idioma espaÃ±ol los subtitulos."
      ],
      "metadata": {
        "id": "HpTi1P8P-zq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def translate(lines):\n",
        "  translates = []\n",
        "  translator = pipeline(\"translation_en_to_es\",model=\"Helsinki-NLP/opus-mt-en-es\")\n",
        "  for line in lines:\n",
        "    translation = translator(line)\n",
        "    translates.append(translation[0][\"translation_text\"])\n",
        "  return translates\n",
        "\n",
        "def open_file(path):\n",
        "    #Open the file\n",
        "    file = open(path, \"r\")\n",
        "    # Read a line of the file until there are no more lines\n",
        "    # Remove the return character from each line.\n",
        "    # Return the list of lines.\n",
        "    lines = file.read().splitlines()\n",
        "    # Close the file\n",
        "    file.close()\n",
        "    return lines\n",
        "\n",
        "# Copy a file and other path and rename it\n",
        "def copy_srt(src, dst):\n",
        "    if os.path.isfile(src):\n",
        "      shutil.copy(src, dst)\n",
        "      print(\"File copied successfully.\")\n",
        "\n",
        "# Searches a text file for a matching line and replaces it with a given value\n",
        "def replace_line(filename, search, replace):\n",
        "    with open(filename, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    with open(filename, 'w') as f:\n",
        "        for line in lines:\n",
        "            if search in line:\n",
        "                line = replace\n",
        "            f.writelines(line)\n",
        "\n",
        "def replace_srt(filename):\n",
        "  searches = open_file(filename)\n",
        "  replaces = translate(searches)\n",
        "  for i in range(0, len(searches)):\n",
        "    replace_line(filename, searches[i], replaces[i])"
      ],
      "metadata": {
        "id": "cq0owE9FHxmO"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copy_srt(\"/content/audio_transcription/output.mp4.srt\", \"/content/audio_transcription/output.es.srt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbO1FJ9yNz-Y",
        "outputId": "d7c5ed8f-7d23-487f-f4a3-88518edb0bcc"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File copied successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "replace_srt(\"/content/audio_transcription/output.es.srt\")"
      ],
      "metadata": {
        "id": "OwXcbCQgZpYF"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!ffmpeg -i \"/content/output.mp4\" -i \"/content/audio_transcription/output.mp4.srt\" -i \"/content/audio_transcription/output.es.srt\" -map 0:v -map 0:a -map 1 -map 2 -c:v copy -c:a copy -c:s srt -metadata:s:s:0 language=eng -metadata:s:s:1 language=es output.mkv"
      ],
      "metadata": {
        "id": "pQRDMORWnU2y"
      },
      "execution_count": 46,
      "outputs": []
    }
  ]
}